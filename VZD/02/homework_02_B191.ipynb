{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 2 - předzpracování dat a binární klasifikace (do 10. listopadu)\n",
    "\n",
    "  * Cílem tohoto úkolu je vyzkoušet si naučit prediktivní model pro binární klasifikaci.\n",
    "  * Budete se muset vypořádat s příznaky, které jsou různých typů a které bude třeba nějakým způsobem převést do číselné reprezentace.\n",
    "    \n",
    "> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n",
    "\n",
    "## Zdroj dat\n",
    "\n",
    "Budeme se zabývat predikcí přežití pasažérů Titaniku.\n",
    "K dispozici máte trénovací data v souboru **data.csv** a data na vyhodnocení v souboru **evaluation.csv**.\n",
    "\n",
    "#### Seznam příznaků:\n",
    "* survived - zda přežil, 0 = Ne, 1 = Ano, **vysvětlovaná proměnná**, kterou chcete predikovat\n",
    "* pclass - Třída lodního lístku, 1 = první, 2 = druhá, 3 = třetí\n",
    "* name - jméno\n",
    "* sex - pohlaví\n",
    "* age - věk v letech\n",
    "* sibsp\t- počet sourozenců / manželů, manželek na palubě\n",
    "* parch - počet rodičů / dětí na palubě\n",
    "* ticket - číslo lodního lístku\n",
    "* fare - cena lodního lístku\n",
    "* cabin\t- číslo kajuty\n",
    "* embarked\t- místo nalodění, C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "* home.dest - Bydliště/Cíl\n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "**Základní body zadání**, za jejichž (poctivé) vypracování získáte **8 bodů**:\n",
    "  * V Jupyter notebooku načtěte data ze souboru **data.csv**. Vhodným způsobem si je rozdělte na trénovací, testovací a případně i validační množinu (preferujeme ale použití cross-validation).\n",
    "  * Projděte si jednotlivé příznaky a transformujte je do vhodné podoby pro použití ve vybraném klasifikačním modelu.\n",
    "  * Podle potřeby si můžete vytvářet nové příznaky (na základě existujících), například tedy můžete vytvořit příznak měřící délku jména. Některé příznaky můžete také úplně zahodit.\n",
    "  * Nějakým způsobem se vypořádejte s chybějícími hodnotami.\n",
    "  * Následně si vyberte vhodný klasifikační model z přednášek. Najděte vhodné hyperparametry a určete jeho přesnost (accuracy) na trénovací množině. Také určete jeho přesnost na testovací/validační množině.\n",
    "  * Načtěte vyhodnocovací data ze souboru **evaluation.csv**. Napočítejte predikce pro tyto data (vysvětlovaná proměnná v nich již není). Vytvořte **results.csv** soubor, ve kterém tyto predikce uložíte do dvou sloupců: ID, predikce přežití. Tento soubor nahrajte do repozitáře.\n",
    "\n",
    "**Další body zadání** za případné další body  (můžete si vybrat, maximum bodů za úkol je každopádně 12 bodů):\n",
    "  * (až +4 body) Aplikujte všechny klasifikační modely z přednášek a určete (na základě přesnosti na validační množině), který je nejlepší. Přesnost tohoto nejlepšího modelu odhadněte pomocí testovací množiny. K predikcím na vyhodnocovacích datech využijte tento model.\n",
    "  * (až +4 body) Zkuste použít nějaké (alespoň dvě) netriviální metody doplňování chybějících hodnot u věku. Zaměřte na vliv těchto metod na přesnost predikce výsledného modelu. K predikcím na vyhodnocovacích datech využijte ten přístup, který Vám vyjde jako nejlepší.\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-VZD/homeworks/index.html.\n",
    "  * Odevzdejte nejen Jupyter Notebook, ale i _csv_ soubor(y) s predikcemi pro vyhodnocovací data.\n",
    "  * Opravující Vám může umožnit úkol dodělat či opravit a získat tak další body. **První verze je ale důležitá a bude-li odbytá, budete za to penalizováni**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "# display(data.shape)\n",
    "# display(data.head())\n",
    "# display(data.describe())\n",
    "# display(data.nunique())\n",
    "# display(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zobrazim si informace o sloupcich, ve kterych chybi data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          201\n",
       "fare           1\n",
       "cabin        773\n",
       "embarked       2\n",
       "home.dest    435\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,data.isnull().sum() > 0].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pri pruzkumu dat jsem dosel k nazoru, ze nektera chybejici data si mohu dovolit doplnit na zaklade dat dostupnych pomoci jednoduchych technik\n",
    "    * **Fare** chybi jen v jednom radku => doplnim hodnotou prumeru\n",
    "    * **Embarked** chybi ve dvou radcich, doplnim informaci nejcastejsim hodnotou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doplneni radku s chybejici fare hodnotou\n",
    "indexOfMissingFareRow = data.loc[data.fare.isnull()].index\n",
    "data.loc[indexOfMissingFareRow, 'fare'] = data.loc[data.fare.notnull()]['fare'].mean()\n",
    "\n",
    "# moznost, kde misto prumeru chybejici data nahradim medianem\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "# data[['fare']] = imputer.fit_transform(data[['fare']])\n",
    "\n",
    "# doplneni radku s chybejici embarked hodnotou\n",
    "mostCommonEmbarkedValue = data['embarked'].value_counts().index[0]\n",
    "for i, row in data.loc[data.embarked.isnull()].iterrows():\n",
    "    data.at[i, 'embarked'] = mostCommonEmbarkedValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **cabin** sloupec sice chybi ve vetsine pripadu, ale docetl jsem se, ze informace o kabinach byly dochovany u vsech lidi, kteri cestovali 1. tridou + u lidi, kteri prezili, takze si vytvorim novy sloupec _cabin_info_ , ktery bude zastupovat zda je udaj o kabine dostupny, ci nikoli\n",
    "    * po ozkouseni mi to vysledne hodnoty nijak nezlepsovalo, po _x_ pokusech mi prislo, ze to naopak zhorsovalo vysledky, a proto jsem se rozhodl tuto informaci nevyuzit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['cabin_info'] = data['cabin'].notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pokus o rozliseni jednotlivych kabin dle podlazi (prvni pismeno z nazvu cabiny), kde jsem nedostupnym udajum priradil priznak _N_\n",
    "    * po aplikaci jsem zaznamenal vyrazne zhorseni vysledku -> takze jsem ve finale take nevyuzil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in data.loc[data.cabin.notnull()].iterrows():\n",
    "#     data.at[i, 'cabin'] = row['cabin'][slice(1)]\n",
    "    \n",
    "# for i, row in data.loc[data.cabin.isnull()].iterrows():\n",
    "#     data.at[i, 'cabin'] = 'N'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dropnu sloupce, ktere jsou nerelevantni pro predpoved nasich dat\n",
    "    * ticket -> cislo lodniho listku podle me neni relevantni vuci tomu kdo prezil\n",
    "    * name -> jmena take\n",
    "    * home.dest -> take nejspise nemelo vliv a velke mnozstvi chybejicich hodnot me vedlo k rozhodnuti tento sloupec dropnout\n",
    "    * cabin -> chybi 773 z 1000 dat a i pri pokusech vytezit z dostupnych informaci nejakeho zlepseni sem nedospel k uspesnemu zaveru, proto i tento sloupec vyrazuji\n",
    "    * ID -> ID cestujiciho v datasetu take neni relevantni info, z ktereho bychom meli vychazet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['ticket', 'name', 'home.dest', 'cabin', 'ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kontrola, ze nyni jiz pouze sloupec **age** obsahuje chybejici data, ta doplnim v nasledujici casti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in columns:\n",
      "age    201\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Missing data in columns:')\n",
    "print(data.loc[:,data.isnull().sum() > 0].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nejdrive zmenim textove priznaky na kategorialni (jedna se o **sex** a **embarked** sloupce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = data.select_dtypes('object').columns\n",
    "# display(data[string_cols].nunique())\n",
    "data[string_cols] = data[string_cols].astype('category').apply(lambda x: x.cat.codes)\n",
    "# data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napadly me dva zpusoby jak doplnit **age** hodnotu, tam kde chybi\n",
    "* pomoci medianu\n",
    "* pomoci kNN regressoru\n",
    "Po ozkouseni obou variant sem k vyrazne lepsim vysledkum dochazel u pouziti prvni zminene metody (az o 10% zlepseni na testovacich datech), proto je pouziti kNN regressoru nize zakomentovano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "data[['age']] = imputer.fit_transform(data[['age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro kNN regressor nejdrive data rozdelim na 3 casti (trenovaci, validacni a testovaci) a pak na vyplnenych **age** sloupcich v trenovacich datech naucim kNN regressor predpovidat hodnotu veku, tu pak pripadne pouziji na zbytek trenovacich dat, data validacni a data testovaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomSeed = 21; # just so I fix it and always get the same results\n",
    "\n",
    "# split data to training, validation and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(data.drop(columns = ['survived']), data['survived'], test_size=0.25, random_state=randomSeed)\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, test_size=0.25, random_state=randomSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# XtrainWithAge = Xtrain[Xtrain['age'].notnull()]\n",
    "# XtrainNoAge = Xtrain[Xtrain['age'].isnull()]\n",
    "\n",
    "# # divide other data sets to \"withAgeFilled\" and \"missingAgeValue\"\n",
    "# XvalidWithAge = Xvalid[Xvalid['age'].notnull()]\n",
    "# XvalidNoAge = Xvalid[Xvalid['age'].isnull()]\n",
    "# XtestWithAge = Xtest[Xtest['age'].notnull()]\n",
    "# XtestNoAge = Xtest[Xtest['age'].isnull()]\n",
    "\n",
    "# # train on filled values in training data\n",
    "# XtrainAge = XtrainWithAge.drop(columns = ['age'])\n",
    "# YtrainAge = XtrainWithAge['age']\n",
    "\n",
    "# # data to fill\n",
    "# XtrainPredictAge = XtrainNoAge.drop(columns = ['age'])\n",
    "# XvalidPredictAge = XvalidNoAge.drop(columns = ['age'])\n",
    "# XtestPredictAge = XtestNoAge.drop(columns = ['age'])\n",
    "\n",
    "# # train\n",
    "# knn = KNeighborsRegressor(n_neighbors=5)\n",
    "# knn.fit(XtrainAge,YtrainAge)\n",
    "\n",
    "# # predict values\n",
    "# YtrainPredictAge = knn.predict(XtrainPredictAge)\n",
    "# YvalidPredictAge = knn.predict(XvalidPredictAge)\n",
    "# YtestPredictAge = knn.predict(XtestPredictAge)\n",
    "\n",
    "# # fill values\n",
    "# XtrainNoAge['age'] = YtrainPredictAge\n",
    "# XvalidNoAge['age'] = YvalidPredictAge\n",
    "# XtestNoAge['age'] = YtestPredictAge\n",
    "\n",
    "# # concat data\n",
    "# Xtrain = pd.concat([XtrainWithAge, XtrainNoAge])\n",
    "# Xvalid = pd.concat([XvalidWithAge, XvalidNoAge])\n",
    "# Xtest = pd.concat([XtestWithAge, XtestNoAge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kontrola zda jsou jiz vsechny sloupce vyplnene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Xtrain.isnull().sum() == 0)\n",
    "# print(Xvalid.isnull().sum() == 0)\n",
    "# print(Xtest.isnull().sum() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vytvorena a pripravena data jiz menit nebudu, budu si vzdy vytvaret pro kazdy model jejich kopie a nad temi dane modely a predikce spoustet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyComputedData():\n",
    "    XtrainCopy = Xtrain.copy()\n",
    "    YtrainCopy = Ytrain.copy() \n",
    "    XvalidCopy = Xvalid.copy() \n",
    "    YvalidCopy = Yvalid.copy() \n",
    "    XtestCopy = Xtest.copy() \n",
    "    YtestCopy = Ytest.copy()\n",
    "    return XtrainCopy, YtrainCopy, XvalidCopy, YvalidCopy, XtestCopy, YtestCopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DECISION TREE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.877224\n",
      "Accuracy on validation set: 0.787234\n",
      "Accuracy on test set: 0.812000\n"
     ]
    }
   ],
   "source": [
    "XtrainCopy, YtrainCopy, XvalidCopy, YvalidCopy, XtestCopy, YtestCopy = copyComputedData()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# build the tree and find the optimal depth of the tree\n",
    "validationAccuracyScoreList = []\n",
    "for depth in range(2,60):\n",
    "    dtc = DecisionTreeClassifier(max_depth=depth, random_state=randomSeed)\n",
    "    dtc.fit(XtrainCopy, YtrainCopy)\n",
    "    validationAccuracyScoreList.append(metrics.accuracy_score(YvalidCopy, dtc.predict(XvalidCopy)))\n",
    "\n",
    "optimalDepth = np.argmax(validationAccuracyScoreList) + 1\n",
    "\n",
    "# predict values with the optimal depth\n",
    "dtc = DecisionTreeClassifier(max_depth=optimalDepth, random_state=randomSeed)\n",
    "dtc.fit(XtrainCopy, YtrainCopy)\n",
    "\n",
    "YtrainPrediction = dtc.predict(XtrainCopy)\n",
    "YvalidPrediction = dtc.predict(XvalidCopy)\n",
    "YtestPrediction = dtc.predict(XtestCopy)\n",
    "\n",
    "print('Accuracy on train set: {0:.6f}'.format(metrics.accuracy_score(YtrainCopy, YtrainPrediction)))\n",
    "print('Accuracy on validation set: {0:.6f}'.format(metrics.accuracy_score(YvalidCopy, YvalidPrediction)))\n",
    "print('Accuracy on test set: {0:.6f}'.format(metrics.accuracy_score(YtestCopy, YtestPrediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bagging method\n",
      "Accuracy on train set: 0.882562\n",
      "Accuracy on validation set: 0.813830\n",
      "Accuracy on test set: 0.800000\n"
     ]
    }
   ],
   "source": [
    "XtrainCopy, YtrainCopy, XvalidCopy, YvalidCopy, XtestCopy, YtestCopy = copyComputedData()\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# search these ranges of parameters to find which parameter produces the best result\n",
    "paramGrid = {\n",
    "    'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 70, 100, 150, 190],\n",
    "    'max_depth': range(3,42)\n",
    "}\n",
    "paramCombinations = ParameterGrid(paramGrid)\n",
    "\n",
    "# train the RandomForestClassifier for each combination of parameters\n",
    "validationAccuracyScoreList = []\n",
    "for params in paramCombinations:\n",
    "    rfc = RandomForestClassifier(**params, random_state=randomSeed)\n",
    "    rfc.fit(XtrainCopy, YtrainCopy)\n",
    "    validationAccuracyScoreList.append(metrics.accuracy_score(YvalidCopy, rfc.predict(XvalidCopy)))\n",
    "\n",
    "# find which parameters give the best result\n",
    "bestParamsBagging = paramCombinations[np.argmax(validationAccuracyScoreList)]\n",
    "\n",
    "#train the model with the best parameters\n",
    "rfc = RandomForestClassifier(**bestParamsBagging, random_state=randomSeed)\n",
    "rfc.fit(XtrainCopy, YtrainCopy)\n",
    "\n",
    "YtrainPrediction = rfc.predict(XtrainCopy)\n",
    "YvalidPrediction = rfc.predict(XvalidCopy)\n",
    "YtestPrediction = rfc.predict(XtestCopy)\n",
    "\n",
    "print('Accuracy of Bagging method')\n",
    "print('Accuracy on train set: {0:.6f}'.format(metrics.accuracy_score(YtrainCopy, YtrainPrediction)))\n",
    "print('Accuracy on validation set: {0:.6f}'.format(metrics.accuracy_score(YvalidCopy, YvalidPrediction)))\n",
    "print('Accuracy on test set: {0:.6f}'.format(metrics.accuracy_score(YtestCopy, YtestPrediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adaboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost method\n",
      "Accuracy on train set: 0.811388\n",
      "Accuracy on validation set: 0.781915\n",
      "Accuracy on test set: 0.804000\n"
     ]
    }
   ],
   "source": [
    "XtrainCopy, YtrainCopy, XvalidCopy, YvalidCopy, XtestCopy, YtestCopy = copyComputedData()\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# try these parameters to find which parameter produces the best result\n",
    "paramGrid = {\n",
    "    'n_estimators': range(1,100,5),\n",
    "    'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.075, 0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1]\n",
    "}\n",
    "paramCombinations = ParameterGrid(paramGrid)\n",
    "\n",
    "# train the AdaBoostClassifier for each combination of parameters\n",
    "validationAccuracyScoreList = []\n",
    "for params in paramCombinations:\n",
    "    abc = AdaBoostClassifier(**params, random_state=randomSeed)\n",
    "    abc.fit(XtrainCopy, YtrainCopy)\n",
    "    validationAccuracyScoreList.append(metrics.accuracy_score(YvalidCopy, abc.predict(XvalidCopy)))\n",
    "\n",
    "# find which parameters give the best result\n",
    "bestParamsAdaBoost = paramCombinations[np.argmax(validationAccuracyScoreList)]\n",
    "\n",
    "#train the model with the best parameters\n",
    "abc = AdaBoostClassifier(**bestParamsAdaBoost, random_state=randomSeed)\n",
    "abc.fit(XtrainCopy, YtrainCopy)\n",
    "\n",
    "YtrainPrediction = abc.predict(XtrainCopy)\n",
    "YvalidPrediction = abc.predict(XvalidCopy)\n",
    "YtestPrediction = abc.predict(XtestCopy)\n",
    "\n",
    "print('Accuracy of AdaBoost method')\n",
    "print('Accuracy on train set: {0:.6f}'.format(metrics.accuracy_score(YtrainCopy, YtrainPrediction)))\n",
    "print('Accuracy on validation set: {0:.6f}'.format(metrics.accuracy_score(YvalidCopy, YvalidPrediction)))\n",
    "print('Accuracy on test set: {0:.6f}'.format(metrics.accuracy_score(YtestCopy, YtestPrediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kNN**\n",
    "* pouzil jsem zakladni minkowskeho metriku\n",
    "* pri znormalizovani hodnot jsem dosahl zlepseni vysledku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of kNN classifier method\n",
      "Accuracy on train set: 0.982206\n",
      "Accuracy on validation set: 0.797872\n",
      "Accuracy on test set: 0.784000\n"
     ]
    }
   ],
   "source": [
    "XtrainCopy, YtrainCopy, XvalidCopy, YvalidCopy, XtestCopy, YtestCopy = copyComputedData()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math\n",
    "    \n",
    "# try these parameters to find which parameter produces the best result\n",
    "paramGrid = {\n",
    "    'n_neighbors' : range(2,21),\n",
    "    'p': [1,2],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "paramCombinations = ParameterGrid(paramGrid)\n",
    "\n",
    "# normalize the values\n",
    "XtrainNormalized = (XtrainCopy - XtrainCopy.min(axis=0))/(XtrainCopy.max(axis = 0) - XtrainCopy.min(axis = 0))\n",
    "XvalidNormalized = (XvalidCopy - XvalidCopy.min(axis=0))/(XvalidCopy.max(axis = 0) - XvalidCopy.min(axis = 0))\n",
    "XtestNormalized = (XtestCopy - XtestCopy.min(axis=0))/(XtestCopy.max(axis = 0) - XtestCopy.min(axis = 0))\n",
    "\n",
    "# train the kNN for each combination of parameters\n",
    "validationAccuracyScoreList = []\n",
    "for params in paramCombinations:\n",
    "    kNN = KNeighborsClassifier(**params)\n",
    "    kNN.fit(XtrainNormalized, YtrainCopy)\n",
    "    validationAccuracyScoreList.append(metrics.accuracy_score(YvalidCopy, kNN.predict(XvalidNormalized)))\n",
    "    \n",
    "# find which parameters give the best result\n",
    "bestParamsKNN = paramCombinations[np.argmax(validationAccuracyScoreList)]\n",
    "\n",
    "#train the model with the best parameters\n",
    "kNN = KNeighborsClassifier(**bestParamsKNN)\n",
    "kNN.fit(XtrainNormalized, YtrainCopy)\n",
    "\n",
    "YtrainPrediction = kNN.predict(XtrainNormalized)\n",
    "YvalidPrediction = kNN.predict(XvalidNormalized)\n",
    "YtestPrediction = kNN.predict(XtestNormalized)\n",
    "\n",
    "print('Accuracy of kNN classifier method')\n",
    "print('Accuracy on train set: {0:.6f}'.format(metrics.accuracy_score(YtrainCopy, YtrainPrediction)))\n",
    "print('Accuracy on validation set: {0:.6f}'.format(metrics.accuracy_score(YvalidCopy, YvalidPrediction)))\n",
    "print('Accuracy on test set: {0:.6f}'.format(metrics.accuracy_score(YtestCopy, YtestPrediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakonec jsem se rozhodl pro vyhodnoceni _evaluation_ datasetu pouzit **Adaboost**\n",
    "* v _evaluation.csv_ take chybeli pouze data ze 3 sloupcu, zachazel jsem s nimi tedy stejnym zpusobem jako s trenovacimi daty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationData = pd.read_csv('evaluation.csv')\n",
    "# display(result.info())\n",
    "# result.loc[:,result.isnull().sum() > 0].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  survived\n",
       "0  1000         0\n",
       "1  1001         0\n",
       "2  1002         0\n",
       "3  1003         0\n",
       "4  1004         0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract ID's\n",
    "ids = evaluationData['ID'].values\n",
    "\n",
    "# preprocess data\n",
    "# drop columns\n",
    "evaluationData.drop(columns=['ticket', 'name', 'home.dest', 'cabin', 'ID'], inplace=True)\n",
    "# fill age values\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "evaluationData[['age']] = imputer.fit_transform(evaluationData[['age']])\n",
    "# change text variables to categorial\n",
    "string_cols = evaluationData.select_dtypes('object').columns\n",
    "evaluationData[string_cols] = evaluationData[string_cols].astype('category').apply(lambda x: x.cat.codes)\n",
    "\n",
    "# predict by the trained AdaBoost from above\n",
    "YevaluationDatePrediction = abc.predict(evaluationData)\n",
    "\n",
    "evaluationData['ID'] = ids\n",
    "evaluationData['survived'] = YevaluationDatePrediction\n",
    "evaluationData.drop(columns=['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked'], inplace=True)\n",
    "\n",
    "evaluationData.to_csv('results.csv')\n",
    "evaluationData.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
